# Canonical integration profile for the local ChatMock sidecar stack.
# Copy into your app .env (or source directly) when targeting this lab.

LLM_PROVIDER=chatmock
LLM_BASE_URL=http://localhost:8000/v1
LLM_MODEL=gpt-5-high
LLM_API_KEY=key
LLM_TIMEOUT_MS=900000

# Async control plane (served by eval-bench at :4000)
ASYNC_CONTROL_BASE_URL=http://localhost:4000/api
ASYNC_MAX_IN_FLIGHT=1
ASYNC_QUEUE_MAX_DEPTH=120
ASYNC_RETRY_MAX_ATTEMPTS=2
ASYNC_RETRY_BASE_MS=1500
ASYNC_RETRY_MAX_DELAY_MS=45000
ASYNC_AUTH_COOLDOWN_MS=300000
ASYNC_CHALLENGE_COOLDOWN_MS=90000
ASYNC_RATE_COOLDOWN_MS=45000
ASYNC_DEGRADED_COOLDOWN_MS=15000
